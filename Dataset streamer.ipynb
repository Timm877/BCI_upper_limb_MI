{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a977ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylsl import StreamInfo, StreamOutlet\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8350b12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignalsOutlet:\n",
    "    def __init__(self, trans_type,\n",
    "                 fs, channels, name='NFBLab_data1'):\n",
    "        self.info = StreamInfo(name=name, type= trans_type, channel_count= channels, source_id='nfblab42',\n",
    "                               nominal_srate=fs)\n",
    "        self.info.desc().append_child_value(\"manufacturer\", \"BioSemi\")\n",
    "        #channels = self.info.desc().append_child(\"channels\")\n",
    "        #for c in signals:\n",
    "        #    channels.append_child(\"channel\").append_child_value(\"name\", c)\n",
    "        self.outlet = StreamOutlet(self.info)\n",
    "\n",
    "    def push_sample(self, data):\n",
    "        self.outlet.push_sample(data)\n",
    "\n",
    "    def push_repeated_chunk(self, data, n=1):\n",
    "        #chunk = repeat(data, n).reshape(-1, n).T.tolist()\n",
    "        #self.outlet.push_chunk(chunk)\n",
    "        for k in range(n):\n",
    "            self.outlet.push_sample(data)\n",
    "\n",
    "    def push_chunk(self, data, n=1):\n",
    "        self.outlet.push_chunk(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86cb9a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "sOut1 = SignalsOutlet('EEG1',250,17) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e9b6628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X01 data loaded to dataset & total length - 10\n",
      "X02 data loaded to dataset & total length - 20\n",
      "X03 data loaded to dataset & total length - 30\n",
      "X04 data loaded to dataset & total length - 40\n",
      "X05 data loaded to dataset & total length - 50\n",
      "X06 data loaded to dataset & total length - 60\n",
      "X07 data loaded to dataset & total length - 70\n",
      "X08 data loaded to dataset & total length - 80\n",
      "X09 data loaded to dataset & total length - 90\n"
     ]
    }
   ],
   "source": [
    "# load data into dict entry\n",
    "sampling_frequency = 250 \n",
    "# testing here for 8 electrodes:\n",
    "electrode_names =  ['FZ', 'C3', 'CZ', 'C4', 'PZ', 'PO7', 'OZ', 'PO8','AccX','AccY','AccZ','Gyro1','Gyro2','Gyro3',\n",
    "                                  'Battery','Counter','Validation']\n",
    "dataset_full = {}\n",
    "trials_amount = 0\n",
    "\n",
    "subjects = ['X01', 'X02','X03','X04','X05','X06','X07','X08','X09']\n",
    "#subjects = ['X02'] #dry subjects\n",
    "for subject in subjects :\n",
    "    folder_path = Path(f'./data/openloop/{subject}/openloop')\n",
    "    #folder_path = Path(f'./data/dry/{subject}/openloop')\n",
    "    for instance in os.scandir(folder_path):\n",
    "        if instance.path.endswith('.csv'): \n",
    "            trials_amount +=1\n",
    "            #print(f'adding_{instance} to dataset...')\n",
    "            sig = pd.read_csv(instance.path)\n",
    "            X = sig.loc[:,electrode_names]\n",
    "            y = sig.loc[:,'Class']\n",
    "            dataset_full[str(instance)] = pd.concat([X], axis=1)\n",
    "    print(f'{subject} data loaded to dataset & total length - {len(dataset_full)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d300d3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n",
      "stream done\n"
     ]
    }
   ],
   "source": [
    "sub2stream = 'X01'\n",
    "import time\n",
    "for dir_entry in list(dataset_full.keys()):\n",
    "    if sub2stream in dir_entry:\n",
    "        for j in range(10):\n",
    "            #print(dataset_full[dir_entry].shape[0])\n",
    "            for i in range(0, dataset_full[dir_entry].shape[0]):\n",
    "                sOut1.push_sample(list(dataset_full[dir_entry].iloc[i]))\n",
    "                time.sleep(1/250)\n",
    "                if i == dataset_full[dir_entry].shape[0]-1:\n",
    "                    print('stream done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2972f086",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b6048e62c6ef2da1fc684b9cfa161fc0471ee4bbc702e058de876b1b813933a9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('UnicornBCI')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
