{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "c:\\Users\\Tim de Boer\\anaconda3\\envs\\UnicornBCI\\lib\\site-packages\\pyglet\\media\\codecs\\wmf.py:838: UserWarning: [WinError -2147417850] Kan threadmodus niet wijzigen nadat deze is ingesteld\n",
      "  warnings.warn(str(err))\n"
     ]
    }
   ],
   "source": [
    "# code for storing subject and trial info\n",
    "from psychopy import gui, visual, core, data, event, logging, clock, colors, layout\n",
    "# GUI for saving data # Store info about the experiment session\n",
    "expName = 'game'\n",
    "exType = 'wet'\n",
    "expInfo = {'participant': 'X01','type': exType, 'expName' : expName, 'sessionNum': 'session3'}\n",
    "dlg = gui.DlgFromDict(dictionary=expInfo, sortKeys=False, title=expName)\n",
    "if dlg.OK == False:\n",
    "    core.quit()  # user pressed cancel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tim de Boer\\anaconda3\\envs\\UnicornBCI\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import realtime_utils as utils\n",
    "import torch\n",
    "import pickle\n",
    "#INIT\n",
    "filt_ord = 2\n",
    "freq_limits = np.asarray([[1,100]]) \n",
    "freq_limits_names = ['1_100Hz']\n",
    "sample_duration = 125\n",
    "sampling_frequency = 250\n",
    "electrode_names =  ['FZ', 'C3', 'CZ', 'C4', 'PZ', 'PO7', 'OZ', 'PO8']\n",
    "filters = utils.init_filters(freq_limits, sampling_frequency, filt_type = 'bandpass', order=filt_ord)\n",
    "segments, labels, predictions = [], [], []\n",
    "total_outlier = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EEGNET(\n",
       "  (temporal): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(1, 64), stride=(1, 1), padding=same, bias=False)\n",
       "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (spatial): Sequential(\n",
       "    (0): Conv2d(8, 16, kernel_size=(8, 1), stride=(1, 1), groups=8, bias=False)\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ELU(alpha=True)\n",
       "  )\n",
       "  (seperable): Sequential(\n",
       "    (0): Conv2d(16, 16, kernel_size=(1, 16), stride=(1, 1), padding=same, groups=16, bias=False)\n",
       "    (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "    (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ELU(alpha=True)\n",
       "  )\n",
       "  (avgpool1): AvgPool2d(kernel_size=[1, 5], stride=[1, 5], padding=0)\n",
       "  (avgpool2): AvgPool2d(kernel_size=[1, 5], stride=[1, 5], padding=0)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       "  (view): Sequential(\n",
       "    (0): Flatten()\n",
       "  )\n",
       "  (fc2): Linear(in_features=320, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init DL model\n",
    "subject = expInfo['participant']\n",
    "net = utils.EEGNET()\n",
    "path = r'final_models/models_for_closedloop/EEGNET_X01_best_finetune_session3' # TODO update path later\n",
    "net.load_state_dict(torch.load(path, map_location=torch.device('cpu')))\n",
    "net = net.float()\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynput.keyboard import Key, Controller\n",
    "keyboard_game = Controller()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conducting game experiment for subject : X04\n",
      "No. of Practice Trials before : 2\n",
      "Trial Number : 03\n",
      "Actual Trial\n",
      "Total number of trials as of now : 5\n",
      "Saving file as ..  X04_2022-06-09_game_wet_03.csv\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([0])\n",
      "prediction: tensor([0])\n",
      "prediction: tensor([0])\n",
      "prediction: tensor([0])\n",
      "prediction: tensor([0])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([0])\n",
      "prediction: tensor([0])\n",
      "prediction: tensor([0])\n",
      "prediction: tensor([0])\n",
      "prediction: tensor([0])\n",
      "prediction: tensor([0])\n",
      "prediction: tensor([0])\n",
      "prediction: tensor([0])\n",
      "prediction: tensor([0])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([1])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "prediction: tensor([2])\n",
      "OUTLIER\n",
      "OUTLIER\n",
      "OUTLIER\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Tim de Boer\\Documents\\VU\\Master_Artificial_Intelligence\\9_BCI_MasterProject\\BCI_Code\\unicorn_MI_BCI\\closed_loop\\8_closedloop_gamecapture.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 79>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tim%20de%20Boer/Documents/VU/Master_Artificial_Intelligence/9_BCI_MasterProject/BCI_Code/unicorn_MI_BCI/closed_loop/8_closedloop_gamecapture.ipynb#ch0000004?line=77'>78</a>\u001b[0m key \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tim%20de%20Boer/Documents/VU/Master_Artificial_Intelligence/9_BCI_MasterProject/BCI_Code/unicorn_MI_BCI/closed_loop/8_closedloop_gamecapture.ipynb#ch0000004?line=78'>79</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m finished:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Tim%20de%20Boer/Documents/VU/Master_Artificial_Intelligence/9_BCI_MasterProject/BCI_Code/unicorn_MI_BCI/closed_loop/8_closedloop_gamecapture.ipynb#ch0000004?line=80'>81</a>\u001b[0m     sample, timestamp \u001b[39m=\u001b[39m inlet\u001b[39m.\u001b[39;49mpull_sample()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tim%20de%20Boer/Documents/VU/Master_Artificial_Intelligence/9_BCI_MasterProject/BCI_Code/unicorn_MI_BCI/closed_loop/8_closedloop_gamecapture.ipynb#ch0000004?line=82'>83</a>\u001b[0m     res \u001b[39m=\u001b[39m [timestamp] \u001b[39m+\u001b[39m sample \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tim%20de%20Boer/Documents/VU/Master_Artificial_Intelligence/9_BCI_MasterProject/BCI_Code/unicorn_MI_BCI/closed_loop/8_closedloop_gamecapture.ipynb#ch0000004?line=83'>84</a>\u001b[0m     data_dict \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mupdate_data(data_dict,res)\n",
      "File \u001b[1;32mc:\\Users\\Tim de Boer\\anaconda3\\envs\\UnicornBCI\\lib\\site-packages\\pylsl\\pylsl.py:803\u001b[0m, in \u001b[0;36mStreamInlet.pull_sample\u001b[1;34m(self, timeout, sample)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Tim%20de%20Boer/anaconda3/envs/UnicornBCI/lib/site-packages/pylsl/pylsl.py?line=799'>800</a>\u001b[0m     assign_to \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Tim%20de%20Boer/anaconda3/envs/UnicornBCI/lib/site-packages/pylsl/pylsl.py?line=801'>802</a>\u001b[0m errcode \u001b[39m=\u001b[39m c_int()\n\u001b[1;32m--> <a href='file:///c%3A/Users/Tim%20de%20Boer/anaconda3/envs/UnicornBCI/lib/site-packages/pylsl/pylsl.py?line=802'>803</a>\u001b[0m timestamp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_pull_sample(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj, byref(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msample),\n\u001b[0;32m    <a href='file:///c%3A/Users/Tim%20de%20Boer/anaconda3/envs/UnicornBCI/lib/site-packages/pylsl/pylsl.py?line=803'>804</a>\u001b[0m                                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchannel_count, c_double(timeout),\n\u001b[0;32m    <a href='file:///c%3A/Users/Tim%20de%20Boer/anaconda3/envs/UnicornBCI/lib/site-packages/pylsl/pylsl.py?line=804'>805</a>\u001b[0m                                 byref(errcode))\n\u001b[0;32m    <a href='file:///c%3A/Users/Tim%20de%20Boer/anaconda3/envs/UnicornBCI/lib/site-packages/pylsl/pylsl.py?line=805'>806</a>\u001b[0m handle_error(errcode)\n\u001b[0;32m    <a href='file:///c%3A/Users/Tim%20de%20Boer/anaconda3/envs/UnicornBCI/lib/site-packages/pylsl/pylsl.py?line=806'>807</a>\u001b[0m \u001b[39mif\u001b[39;00m timestamp:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "#psychopy libraries for running the visual cues\n",
    "from psychopy import gui, visual, core, data, event, logging, clock, colors, layout\n",
    "import psychopy.iohub as io\n",
    "from psychopy.hardware import keyboard\n",
    "#numpy and pd for data storing and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import  shuffle\n",
    "# misc libraries to structure the cues properly and save it with date time and stuff\n",
    "import time\n",
    "from datetime import date\n",
    "from pathlib import Path\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import msvcrt\n",
    "import datetime\n",
    "# lab streaming layer library to capture the data sent by unicorn EEG headset\n",
    "from pylsl import StreamInlet, resolve_stream\n",
    "\n",
    "#change path of folders according to your needs\n",
    "# Data file name stem = absolute path + name; later add .psyexp, .csv, .log, etc\n",
    "result_path = Path(f'./Expdata/Subjects/'+exType+'/'+expInfo['participant']+'/'+expInfo['sessionNum']+'/'+expName+'/')\n",
    "result_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "columns=['Time','FZ', 'C3', 'CZ', 'C4', 'PZ', 'PO7', 'OZ', 'PO8','AccX','AccY','AccZ','Gyro1','Gyro2','Gyro3',\n",
    "                                  'Battery','Counter','Validation']\n",
    "\n",
    "data_dict = dict((k, []) for k in columns)\n",
    "current_seg = pd.DataFrame()\n",
    "total_MI_outliers = 0\n",
    "all_MI_segments, all_MI_labels, predictions = [], [], []\n",
    "\n",
    "MI_dict = {'MI_segments' : [], 'predictions': []}\n",
    "\n",
    "# below code is for initializing the streaming layer which will help us capture data later\n",
    "finished = False\n",
    "streams = resolve_stream()\n",
    "inlet = StreamInlet(streams[0])\n",
    "\n",
    "# Auto updating trial numbers\n",
    "trial_list = []\n",
    "for instance in os.scandir(result_path):\n",
    "        if instance.path.endswith('.csv'):\n",
    "            length = len(instance.path)\n",
    "            trial_list.append(int(instance.path[length-5]))\n",
    "\n",
    "if len(trial_list) == 0:\n",
    "    session = '01'\n",
    "elif len(trial_list) < 9 :\n",
    "    session = len(trial_list) + 1\n",
    "    session = '0' + str(session)\n",
    "else :\n",
    "    session = str(len(trial_list) + 1)\n",
    "\n",
    "print(f\"Conducting {expName} experiment for subject :\", expInfo['participant'])\n",
    "print('No. of Practice Trials before :', 2)\n",
    "print(\"Trial Number :\", session)\n",
    "\n",
    "print('Actual Trial')\n",
    "print('Total number of trials as of now :', int(session) + 2)\n",
    "results_fname = expInfo['participant']+'_'+str(date.today())+'_'+expName+'_'+ expInfo['type']+'_'+session+'.csv'\n",
    "print(\"Saving file as .. \", results_fname)\n",
    "\n",
    "\n",
    "Fs = 250 # sampling frequency of Unicorn EEG cap\n",
    "temp = []\n",
    "times = []\n",
    "#start = time.time()\n",
    "flush = [17*Fs, 37*Fs, 57*Fs, 77*Fs, 97*Fs, 117*Fs]\n",
    "\n",
    "initial = 0\n",
    "final = 125\n",
    "prediction = -1\n",
    "outliers = []\n",
    "key = False\n",
    "while not finished:\n",
    "\n",
    "    sample, timestamp = inlet.pull_sample()\n",
    "    \n",
    "    res = [timestamp] + sample \n",
    "    data_dict = utils.update_data(data_dict,res)\n",
    "\n",
    "    if len(data_dict['FZ']) % 125 == 0:\n",
    "        df, initial, final = utils.segment_dict(initial, final, sample_duration, data_dict)\n",
    "        segment_filt, out, filters = utils.pre_processing(df, electrode_names, filters, \n",
    "                        sample_duration, freq_limits_names, sampling_frequency)\n",
    "        current_seg = utils.concatdata(current_seg,segment_filt)   \n",
    "        outliers.append(out)   \n",
    "\n",
    "        # do prediction with current segment and update number\n",
    "        if current_seg.shape[1] == 500:\n",
    "            if sum(outliers) > 0:\n",
    "                total_MI_outliers +=1\n",
    "                print('OUTLIER')\n",
    "                if key:\n",
    "                    keyboard_game.release(key) \n",
    "            else:\n",
    "                all_MI_segments.append(current_seg)\n",
    "                prediction = utils.do_prediction(current_seg, net)\n",
    "                predictions.append(int(prediction[0]))\n",
    "                print(f\"prediction: {prediction}\") \n",
    "                if key:\n",
    "                    keyboard_game.release(key)\n",
    "                if prediction[0] == 1:\n",
    "                    key = Key.right \n",
    "                    keyboard_game.press(key)\n",
    "                elif prediction[0] == 2:\n",
    "                    key = Key.left\n",
    "                    keyboard_game.press(key)\n",
    "            outliers = outliers[1:]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving file MI Data file as ..  X04_2022-06-09_game_wet_03_MIData.pkl\n",
      "Trial Ended\n"
     ]
    }
   ],
   "source": [
    "# making dictionary into a dataframe for saving it as csv\n",
    "record_data = pd.DataFrame.from_dict(data_dict)\n",
    "\n",
    "#saving MI segments in pickle file\n",
    "MI_dict = {'MI_segments' : [], 'predictions': []}\n",
    "MI_dict['MI_segments'] = all_MI_segments\n",
    "MI_dict['predictions'] = predictions\n",
    "\n",
    "result_path = Path(f\"./Expdata/Subjects/{exType}/{subject}/{expInfo['sessionNum']}/{expName}\")\n",
    "exp_type = expInfo['type']\n",
    "MI_fname = f'{subject}_{str(date.today())}_{expName}_{exp_type}_{session}_MIData.pkl'\n",
    "print(\"Saving file MI Data file as .. \", MI_fname)\n",
    "save_file = open(result_path / MI_fname, \"wb\")\n",
    "pickle.dump(MI_dict, save_file)\n",
    "save_file.close()\n",
    "\n",
    "#fname = Path('./Expdata/Subjects/'+expInfo['participant']+'/'+ expName + '/'+results_fname)\n",
    "fname = Path('./Expdata/Subjects/'+exType+'/'+expInfo['participant']+'/'+expInfo['sessionNum']+'/'+expName+'/'+results_fname)\n",
    "record_data.to_csv(fname, index = False)\n",
    "print('Trial Ended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b6048e62c6ef2da1fc684b9cfa161fc0471ee4bbc702e058de876b1b813933a9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('UnicornBCI')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
