{'D': 3, 'activation_type': 'elu', 'batch_size': 256, 'dropout': 0.4, 'epochs': 40, 'filter_sizing': 16, 'learning_rate': 0.001, 'mean_pool': 8, 'network': 'EEGNET', 'receptive_field': 64, 'seed': 42, 'val_subjects': ['X05', 'X06']}
Adding data for data\openloop\intermediate_datafiles\preprocess\TL_1_100Hz\X01_deep.pkl...
Current length of X train: 780.
Current length of X val: 0.
Adding data for data\openloop\intermediate_datafiles\preprocess\TL_1_100Hz\X02_deep.pkl...
Current length of X train: 1556.
Current length of X val: 0.
Adding data for data\openloop\intermediate_datafiles\preprocess\TL_1_100Hz\X03_deep.pkl...
Current length of X train: 2329.
Current length of X val: 0.
Adding data for data\openloop\intermediate_datafiles\preprocess\TL_1_100Hz\X04_deep.pkl...
Current length of X train: 3108.
Current length of X val: 0.
Adding data for data\openloop\intermediate_datafiles\preprocess\TL_1_100Hz\X05_deep.pkl...
Current length of X train: 3108.
Current length of X val: 780.
Adding data for data\openloop\intermediate_datafiles\preprocess\TL_1_100Hz\X06_deep.pkl...
Current length of X train: 3108.
Current length of X val: 1560.
Adding data for data\openloop\intermediate_datafiles\preprocess\TL_1_100Hz\X07_deep.pkl...
Current length of X train: 3886.
Current length of X val: 1560.
Adding data for data\openloop\intermediate_datafiles\preprocess\TL_1_100Hz\X08_deep.pkl...
C:\Users\Tim de Boer\anaconda3\envs\UnicornBCI\lib\site-packages\torch\nn\modules\conv.py:442: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  ..\aten\src\ATen\native\Convolution.cpp:647.)
  return F.conv2d(input, weight, bias, self.stride,
Current length of X train: 4666.
Current length of X val: 1560.
Adding data for data\openloop\intermediate_datafiles\preprocess\TL_1_100Hz\X09_deep.pkl...
Current length of X train: 5446.
Current length of X val: 1560.
trainable parameters: 6867
acc: 0.37564102564102564, f1: 0.37638544319824696
acc: 0.40192307692307694, f1: 0.40425191667793514
acc: 0.4576923076923077, f1: 0.4476744820297533
acc: 0.483974358974359, f1: 0.48182502289596885
acc: 0.55, f1: 0.5373336337076166
acc: 0.5807692307692308, f1: 0.5567997076465777
acc: 0.6076923076923076, f1: 0.5638052797653105
acc: 0.6185897435897436, f1: 0.6017377866429688
acc: 0.6224358974358974, f1: 0.6079616282449002
acc: 0.6333333333333333, f1: 0.6266857903685988
acc: 0.6083333333333333, f1: 0.5938142383782106
acc: 0.6365384615384615, f1: 0.623688474179545
acc: 0.6352564102564102, f1: 0.6356297224962298
acc: 0.6096153846153847, f1: 0.5830465695305576
acc: 0.6410256410256411, f1: 0.6366259658104398
acc: 0.6384615384615384, f1: 0.6327441810219877
acc: 0.6230769230769231, f1: 0.5703372844367302
acc: 0.6416666666666667, f1: 0.6346909396201469
acc: 0.6378205128205128, f1: 0.6152706076175615
acc: 0.6448717948717949, f1: 0.654364200764337
acc: 0.6339743589743589, f1: 0.6331860640477388
acc: 0.6416666666666667, f1: 0.6486471076222385
acc: 0.6397435897435897, f1: 0.6096390251027988
acc: 0.6339743589743589, f1: 0.6106213355600295
acc: 0.6358974358974359, f1: 0.6232062561508146
acc: 0.6435897435897436, f1: 0.6531940045085692
acc: 0.6294871794871795, f1: 0.5984703930705635
acc: 0.6384615384615384, f1: 0.6270153697582115
acc: 0.6346153846153846, f1: 0.6112502660721271
