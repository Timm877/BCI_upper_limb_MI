{'batch_size': 256, 'epochs': 30, 'receptive_field': 64, 'mean_pool': 8, 'activation_type': 'elu', 'network': 'EEGNET', 'val_subjects': ['X04', 'X06'], 'test_subject': 'X01', 'seed': 42, 'learning_rate': 0.001, 'filter_sizing': 8, 'D': 2, 'dropout': 0.4}
X01
Adding data for data\openloop\intermediate_datafiles\preprocess\TL_1_100Hz\X01_deep.pkl...
Current length of X train: 0.
Current length of X val: 0.
Adding data for data\openloop\intermediate_datafiles\preprocess\TL_1_100Hz\X02_deep.pkl...
Current length of X train: 776.
Current length of X val: 0.
Adding data for data\openloop\intermediate_datafiles\preprocess\TL_1_100Hz\X03_deep.pkl...
Current length of X train: 1549.
Current length of X val: 0.
Adding data for data\openloop\intermediate_datafiles\preprocess\TL_1_100Hz\X04_deep.pkl...
Current length of X train: 1549.
Current length of X val: 779.
Adding data for data\openloop\intermediate_datafiles\preprocess\TL_1_100Hz\X05_deep.pkl...
Current length of X train: 2329.
Current length of X val: 779.
Adding data for data\openloop\intermediate_datafiles\preprocess\TL_1_100Hz\X06_deep.pkl...
Current length of X train: 2329.
Current length of X val: 1559.
Adding data for data\openloop\intermediate_datafiles\preprocess\TL_1_100Hz\X07_deep.pkl...
Current length of X train: 3107.
Current length of X val: 1559.
Adding data for data\openloop\intermediate_datafiles\preprocess\TL_1_100Hz\X08_deep.pkl...
C:\Users\Tim de Boer\anaconda3\envs\UnicornBCI\lib\site-packages\torch\nn\modules\conv.py:442: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  ..\aten\src\ATen\native\Convolution.cpp:647.)
  return F.conv2d(input, weight, bias, self.stride,
Current length of X train: 3887.
Current length of X val: 1559.
Adding data for data\openloop\intermediate_datafiles\preprocess\TL_1_100Hz\X09_deep.pkl...
Current length of X train: 4667.
Current length of X val: 1559.
trainable parameters: 1955
acc: 0.3444515715202053, f1: 0.34193827706663765
acc: 0.34124438742783836, f1: 0.3413483883671637
acc: 0.345734445157152, f1: 0.33606154910395347
acc: 0.3335471456061578, f1: 0.3504232637979033
acc: 0.37716484926234767, f1: 0.3436723059877312
acc: 0.4278383579217447, f1: 0.4209938333752933
acc: 0.4650416933932008, f1: 0.46683269460085075
acc: 0.4894162924951892, f1: 0.4540285074249078
acc: 0.482360487491982, f1: 0.47051850718769467
acc: 0.48813341885824246, f1: 0.48270493928566677
acc: 0.48813341885824246, f1: 0.48538425351840786
acc: 0.49839640795381657, f1: 0.4913039214242176
acc: 0.5169980756895446, f1: 0.505724276007252
acc: 0.490699166132136, f1: 0.4987296062371846
acc: 0.514432328415651, f1: 0.5190380434665871
acc: 0.4996792815907633, f1: 0.4881692638177242
acc: 0.5035279025016036, f1: 0.48666129980904976
acc: 0.50096215522771, f1: 0.5096479395206314
acc: 0.5112251443232841, f1: 0.4941401685639709
acc: 0.5080179602309173, f1: 0.49375680402331484
acc: 0.5067350865939705, f1: 0.517666880998716
acc: 0.5112251443232841, f1: 0.5017139046201601
acc: 0.5163566388710712, f1: 0.5037786849198495
acc: 0.5125080179602309, f1: 0.49541887954044145
acc: 0.5093008338678641, f1: 0.5070286837111048
acc: 0.5105837075048107, f1: 0.5334532327401038
acc: 0.5093008338678641, f1: 0.5141921134316689
acc: 0.5048107761385503, f1: 0.4845758032081231
acc: 0.5214881334188582, f1: 0.5223852272097659
acc: 0.5054522129570237, f1: 0.5046895110213431